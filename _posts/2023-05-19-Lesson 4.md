# Lesson 4
This lesson focused on Natural Language Processing (NLP) and fine tuning a pre-trained NLP model using the Hugging Face Transformers library and didnâ€™t use fastai at all! This concept was very new to me, but I was immediately interested. I thought it was fascinating to think about understanding language both for humans and machines. For a high performing language model, not only do neural networks have to understand how language works in terms of structure but they also need to have knowledge of the content of the language, which is crazy to think about as it could include all sorts of information about the world.

![world](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/7728c864-88c5-4398-9684-aaf22a454974)

The use of NLP for sentiment analysis was another cool concept. This was presenting in the context of determining if an IMDb rating was negative or positive. It reminded me of an application that a friend of mine was working on at a bank, which involved detecting complaints across a variety of platforms in real-time.

This was also my first introduction to the Hugging Face hug where pre-trained models can be found with the idea being that if a model was developed to solve a similar problem or trained using similar data then it's a good starting point for the current problem. 

![standing on the shoulders of giants quote](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/5c096fd6-ed7c-4acd-bb06-c33edbba95c4)

This lesson also introduced me to the concept of overfitting and underfitting. Underfitting is where the model does not fit the data well at all and systematically incorrect:

![underfit example](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/be9656f4-1fb7-417d-8af6-ed8227a25619)

Overfitting is where the model fits the exact data points extremely well:
![overfit example](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/574446f2-1878-4b2a-9118-c25ec5405672)

However results in poor performance with the addition of extra data. It is easy to detect underfitting as the training data will not be well represented. Overfitting is trickier! I was then taught the usefulness of the validation set used when training a model. From the original dataset, ~20% is removed and the model is trained to fit the remaining data points and then performance is tested using the removed data points. Simple but brilliant! 
