# Lesson 4
## Natural Language Processing
This lesson focused on Natural Language Processing (NLP) and fine tuning a pre-trained NLP model using the Hugging Face Transformers library and didnâ€™t use fastai at all! This concept was very new to me, but I was immediately interested. I thought it was fascinating to think about understanding language both for humans and machines. For a high performing language model, not only do neural networks have to understand how language works in terms of structure but they also need to have knowledge of the content of the language, which is crazy to think about as it could include all sorts of information about the world.

![world](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/9aac3b25-00e1-4ad9-b90c-ff9bcef76e0a)

The use of NLP for sentiment analysis was another cool concept. This was presented in the context of determining if an IMDb rating was negative or positive. It reminded me of an application that a friend of mine was working on at a bank, which involved detecting complaints across a variety of platforms in real-time. Other applications include:
- Chatbots & virtual assistants
- Machine translation
- Speech recognition
- Auto-correct

## Hugging Face
Lesson 4 was also my first introduction to Hugging Face where pre-trained models can be found [^1]. These models offer an excellent starting point when working on a new problem especially if they been developed to solve a similar problem or trained using similar data.

![standing on the shoulders of giants quote](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/5c096fd6-ed7c-4acd-bb06-c33edbba95c4)

## Overfitting and Underfitting
This lesson also introduced me to the concept of overfitting and underfitting. Underfitting is where the model does not fit the data well at all and is systematically incorrect and overfitting is where the model fits the exact data points extremely well, however results in poor performance with the addition of extra data. I found this [article](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/) really helped my understanding.

![data fitting](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/c926bfa5-3c17-4036-ab38-20aedf9b2a33)

It is easy to detect underfitting as the training data will not be well represented. Overfitting however is trickier! The usefulness of having a validation set was then made very clear to me. This validation set is formed by removing ~20% of the original dataset before the model is trained to fit the remaining data points. Performance is then tested using the removed validation set, which will reveal overfitting if it has occurred. Simple but brilliant!

[^1]: [Hugging Face Models](https://huggingface.co/models)
