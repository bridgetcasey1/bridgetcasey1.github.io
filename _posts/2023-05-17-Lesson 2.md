# Lesson 2
This lesson focused on the full deep learning application process in the context of **building a bear classifier**.

![image](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/5bb1662c-f2d9-4451-aabc-598963f4b20b)

The journey begins with gathering data, which involved downloading images from the internet as in lesson 1. 
![image](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/75088cc2-9d91-4295-9780-ab2c5d96a9f4)

After this, **the model is trained and then the data is cleaned**. Yes, you heard me correctly. I found this part of the lesson surprising as it makes more sense to me to clean the data and then train the model but by the end of the lesson I was convinced that this was the way. The model was trained as in lesson 1 and then the ```Learner``` created and fine-tuned used to help clean the data:

```
cleaner = ImageClassifierCleaner(learn)
cleaner
```
This brings up a GUI as below:

![image](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/82a7356a-67e3-4b72-9080-cb3ba0c9ab67)

The GUI can be used to delete images that do not fit into any category (e.g. two bears in one image) or to move images to their correct category. One thing I haven't thought too much about is the fact that you can train a model on incorrect data. For example, when searching for black bears an image of a grizzly bear may have been incorrectly labelled elsewhere and so accidentally downloaded and stored as a black bear. The data cleaning post training the model can help us easily identify these mistakes. 

A few other things I found interesting from the lesson included:
- Loss is not just about being right or wrong but about how confident the model is about the classification - 
  - Being right with low confidence
  - Being wrong with high confidence
- How easily a trained model can be transferred to another file for application in a new setting.

# Lesson 3  
Lesson 3 covers the mathematical foundations of deep learning. This is extremely important in my opinion as I believe you should have some idea of the foundations and shouldn't just apply methods blindly. I found the theory behind deep learning more complex than working with  fastai however more simple than I anticipated for how powerful deep learning is.

![image](https://github.com/bridgetcasey1/bridgetcasey1.github.io/assets/113487655/3330cfc6-5482-4abb-8df0-ddad1065fc9e)

Deep learning is a type of machine learning based on artificial neural networks and I found it cool being introduced to the concept of neural networks as an infinitely flexible function with multiple parameters that you adjust to mould to your data and to solve the problem at hand.

# Lesson 4
